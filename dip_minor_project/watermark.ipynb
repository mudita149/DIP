{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3bcb2dab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bcb2dab",
        "outputId": "aee47254-fe85-497b-af42-bd3e0dd9eb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in d:\\anaconda\\lib\\site-packages (1.45.1)\n",
            "Requirement already satisfied: opencv-python-headless in d:\\anaconda\\lib\\site-packages (4.12.0.88)\n",
            "Requirement already satisfied: PyWavelets in d:\\anaconda\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in d:\\anaconda\\lib\\site-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (2.2.3)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in d:\\anaconda\\lib\\site-packages (from streamlit) (5.29.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (19.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in d:\\anaconda\\lib\\site-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in d:\\anaconda\\lib\\site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in d:\\anaconda\\lib\\site-packages (from streamlit) (4.0.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in d:\\anaconda\\lib\\site-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\anaconda\\lib\\site-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in d:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in d:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\anaconda\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in d:\\anaconda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: attrs>=22.2.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install streamlit opencv-python-headless PyWavelets pillow numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fa83fb77",
      "metadata": {
        "id": "fa83fb77"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# watermark_models.py equivalent (VISIBLE + INVISIBLE)\n",
        "# ===============================================================\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pywt\n",
        "import pickle\n",
        "import types\n",
        "\n",
        "# Define module-like namespace for consistent pickling\n",
        "watermark_module = types.ModuleType(\"watermark_models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "db208194",
      "metadata": {
        "id": "db208194"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# INVISIBLE WATERMARK MODEL\n",
        "# ===============================================================\n",
        "class InvisibleWatermarker:\n",
        "    def __init__(self, alpha=0.05, wavelet='haar'):\n",
        "        self.alpha = alpha\n",
        "        self.wavelet = wavelet\n",
        "\n",
        "    def apply(self, main_img, watermark):\n",
        "        main_img = cv2.resize(main_img, (512, 512))\n",
        "        watermark = cv2.resize(watermark, (128, 128))\n",
        "        main_img = np.float32(main_img)\n",
        "        watermark = np.float32(watermark)\n",
        "\n",
        "        watermarked_channels = []\n",
        "        for c in range(3):\n",
        "            LL, (LH, HL, HH) = pywt.dwt2(main_img[:, :, c], self.wavelet)\n",
        "            wm_resized = cv2.resize(watermark[:, :, c], LL.shape)\n",
        "            LL_wm = LL + self.alpha * wm_resized\n",
        "            watermarked_channels.append(pywt.idwt2((LL_wm, (LH, HL, HH)), self.wavelet))\n",
        "\n",
        "        return np.uint8(np.clip(cv2.merge(watermarked_channels), 0, 255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "64a2a36c",
      "metadata": {
        "id": "64a2a36c"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# VISIBLE WATERMARK MODEL\n",
        "# ===============================================================\n",
        "class VisibleWatermarker:\n",
        "    def __init__(self, alpha=0.4, wavelet='haar'):\n",
        "        self.alpha = alpha\n",
        "        self.wavelet = wavelet\n",
        "\n",
        "    def apply(self, main_img, watermark):\n",
        "        main_img = cv2.resize(main_img, (512, 512))\n",
        "        watermark = cv2.resize(watermark, (128, 128))\n",
        "        main_img = np.float32(main_img)\n",
        "        watermark = np.float32(watermark)\n",
        "\n",
        "        visible_channels = []\n",
        "        for c in range(3):\n",
        "            LL, (LH, HL, HH) = pywt.dwt2(main_img[:, :, c], self.wavelet)\n",
        "            wm_resized = cv2.resize(watermark[:, :, c], LL.shape)\n",
        "            LL_visible = cv2.addWeighted(LL, 1.0, wm_resized, self.alpha, 0.0)\n",
        "            visible_channels.append(pywt.idwt2((LL_visible, (LH, HL, HH)), self.wavelet))\n",
        "\n",
        "        return np.uint8(np.clip(cv2.merge(visible_channels), 0, 255))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a1257246",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1257246",
        "outputId": "84124189-eca3-46e8-ce22-b1120accff81"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# IMAGE PREPROCESSOR MODEL\n",
        "# ===============================================================\n",
        "class ImagePreprocessor:\n",
        "    def __init__(self, level=1, to_y=True, target_size=None):\n",
        "        self.level = level\n",
        "        self.to_y = to_y\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def _read_image(self, path_or_array: Union[str, np.ndarray], force_gray: bool = False) -> np.ndarray:\n",
        "        if isinstance(path_or_array, np.ndarray):\n",
        "            img = path_or_array.copy()\n",
        "            if force_gray and img.ndim == 3:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            img = cv2.imread(path_or_array, cv2.IMREAD_UNCHANGED if not force_gray else cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Could not read image: {path_or_array}\")\n",
        "        return img\n",
        "\n",
        "    def _ensure_divisible_by_2pow(self, img: np.ndarray, level: int) -> Tuple[np.ndarray, tuple]:\n",
        "        h, w = img.shape[:2]\n",
        "        factor = 2 ** level\n",
        "        pad_h = (factor - (h % factor)) % factor\n",
        "        pad_w = (factor - (w % factor)) % factor\n",
        "        top, bottom = pad_h // 2, pad_h - pad_h // 2\n",
        "        left, right = pad_w // 2, pad_w - pad_w // 2\n",
        "        padded = cv2.copyMakeBorder(img, top, bottom, left, right, borderType=cv2.BORDER_REFLECT)\n",
        "        return padded, ((top, bottom), (left, right))\n",
        "\n",
        "    def _convert_to_y_channel(self, img_bgr: np.ndarray) -> np.ndarray:\n",
        "        if img_bgr.ndim == 2:\n",
        "            return img_bgr\n",
        "        ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
        "        return ycrcb[:, :, 0]\n",
        "\n",
        "    def apply(self, image_input: Union[str, np.ndarray]) -> np.ndarray:\n",
        "        orig = self._read_image(image_input)\n",
        "        orig_color = orig.copy() if orig.ndim == 3 else None\n",
        "        y = self._convert_to_y_channel(orig) if orig.ndim == 3 and self.to_y else orig.copy()\n",
        "        if self.target_size is not None:\n",
        "            y = cv2.resize(y, (self.target_size[1], self.target_size[0]), interpolation=cv2.INTER_AREA)\n",
        "        y_padded, _ = self._ensure_divisible_by_2pow(y, self.level)\n",
        "        y_eq = cv2.equalizeHist(y_padded.astype(np.uint8))\n",
        "        if orig_color is not None:\n",
        "            y_eq = cv2.cvtColor(y_eq, cv2.COLOR_GRAY2BGR)\n",
        "        return y_eq\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "601b184f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "601b184f",
        "outputId": "5bae2f13-1432-4f62-b1da-a6fb0d937dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All pickle files created successfully:\n",
            "   - invisible_watermarker.pkl\n",
            "   - visible_watermarker.pkl\n",
            "   - image_preprocessing.pkl\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# IMAGE PREPROCESSOR MODEL\n",
        "# ===============================================================\n",
        "class ImagePreprocessor:\n",
        "    def __init__(self, level=1, to_y=True, target_size=None):\n",
        "        self.level = level\n",
        "        self.to_y = to_y\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def _read_image(self, path_or_array: Union[str, np.ndarray], force_gray: bool = False) -> np.ndarray:\n",
        "        if isinstance(path_or_array, np.ndarray):\n",
        "            img = path_or_array.copy()\n",
        "            if force_gray and img.ndim == 3:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            img = cv2.imread(path_or_array, cv2.IMREAD_UNCHANGED if not force_gray else cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Could not read image: {path_or_array}\")\n",
        "        return img\n",
        "\n",
        "    def _ensure_divisible_by_2pow(self, img: np.ndarray, level: int) -> Tuple[np.ndarray, tuple]:\n",
        "        h, w = img.shape[:2]\n",
        "        factor = 2 ** level\n",
        "        pad_h = (factor - (h % factor)) % factor\n",
        "        pad_w = (factor - (w % factor)) % factor\n",
        "        top, bottom = pad_h // 2, pad_h - pad_h // 2\n",
        "        left, right = pad_w // 2, pad_w - pad_w // 2\n",
        "        padded = cv2.copyMakeBorder(img, top, bottom, left, right, borderType=cv2.BORDER_REFLECT)\n",
        "        return padded, ((top, bottom), (left, right))\n",
        "\n",
        "    def _convert_to_y_channel(self, img_bgr: np.ndarray) -> np.ndarray:\n",
        "        if img_bgr.ndim == 2:\n",
        "            return img_bgr\n",
        "        ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
        "        return ycrcb[:, :, 0]\n",
        "\n",
        "    def apply(self, image_input: Union[str, np.ndarray]) -> np.ndarray:\n",
        "        orig = self._read_image(image_input)\n",
        "        orig_color = orig.copy() if orig.ndim == 3 else None\n",
        "        y = self._convert_to_y_channel(orig) if orig.ndim == 3 and self.to_y else orig.copy()\n",
        "        if self.target_size is not None:\n",
        "            y = cv2.resize(y, (self.target_size[1], self.target_size[0]), interpolation=cv2.INTER_AREA)\n",
        "        y_padded, _ = self._ensure_divisible_by_2pow(y, self.level)\n",
        "        y_eq = cv2.equalizeHist(y_padded.astype(np.uint8))\n",
        "        if orig_color is not None:\n",
        "            y_eq = cv2.cvtColor(y_eq, cv2.COLOR_GRAY2BGR)\n",
        "        return y_eq\n",
        "\n",
        "# ===============================================================\n",
        "# SAVE MODELS AS PICKLE FILES\n",
        "# ===============================================================\n",
        "with open(\"invisible_watermarker.pkl\", \"wb\") as f:\n",
        "    pickle.dump(InvisibleWatermarker(), f)\n",
        "\n",
        "with open(\"visible_watermarker.pkl\", \"wb\") as f:\n",
        "    pickle.dump(VisibleWatermarker(), f)\n",
        "\n",
        "with open(\"image_preprocessing.pkl\", \"wb\") as f:\n",
        "    pickle.dump(ImagePreprocessor(), f)\n",
        "\n",
        "print(\"✅ All pickle files created successfully:\")\n",
        "print(\"   - invisible_watermarker.pkl\")\n",
        "print(\"   - visible_watermarker.pkl\")\n",
        "print(\"   - image_preprocessing.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f26d35",
      "metadata": {
        "id": "c5f26d35"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54244e99",
      "metadata": {
        "id": "54244e99"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2ad49a",
      "metadata": {
        "id": "6f2ad49a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b65c91",
      "metadata": {
        "id": "f8b65c91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04baf95f",
      "metadata": {
        "id": "04baf95f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b51a0c4",
      "metadata": {
        "id": "6b51a0c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b9450a",
      "metadata": {
        "id": "69b9450a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
